program: src/train.py
method: bayes  # Bayesian optimization - smart search
metric:
  name: val_accuracy
  goal: maximize

parameters:
  epochs:
    values: [5, 8]  # Reduced from 10 for speed
  
  num_layers:
    values: [3]  # Fixed to 3 - best balance
  
  hidden_size:
    values: [64, 128]  # Only 2 sizes - enough to compare
  
  weight_decay:
    values: [0, 0.0005]  # Skip 0.5 - too aggressive
  
  learning_rate:
    values: [0.001, 0.0001]
  
  optimizer:
    values: ['sgd', 'momentum', 'rmsprop', 'adam', 'nadam']  # Skip nag
  
  batch_size:
    values: [32, 64]  # Larger batches = faster on CPU
  
  weight_init:
    values: ['xavier']  # Xavier is clearly better, skip random
  
  activation:
    values: ['relu', 'tanh']  # Skip sigmoid - too slow
  
  loss:
    value: 'cross_entropy'
  
  dataset:
    value: 'fashion_mnist'

# Early termination - stops bad runs quickly
early_terminate:
  type: hyperband
  min_iter: 2
  eta: 2
  s: 2